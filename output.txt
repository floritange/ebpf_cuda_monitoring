openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/cuda_runtime/lib/libcudart.so.12", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/libc10_cuda.so", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/cudnn/lib/libcudnn.so.8", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/cuda_cupti/lib/libcupti.so.12", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/cufft/lib/libcufft.so.11", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/libcusparseLt-f8b4a9fb.so.0", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/curand/lib/libcurand.so.10", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/cublas/lib/libcublas.so.12", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/root/miniconda3/envs/tangou101/lib/python3.10/site-packages/torch/lib/../../nvidia/cublas/lib/libcublasLt.so.12", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/usr/local/cuda-12.2/lib64/libnvJitLink.so.12", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/lib64/libcuda.so.1", 0x80000, 00) = 3
openat@SYS(AT_FDCWD, "/usr/local/cuda-12.2/lib64/libnvrtc.so", 0x80000, 00) = 3
read@SYS(3, "s restricted to bilinear and bicubic modes and requires a 4-D tensor as input")\n\n    if input.dim() == 3 and mode == "nearest":\n        return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)\n    if input.dim() == 4 and mode == "nearest":\n        return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)\n    if input.dim() == 5 and mode == "nearest":\n        return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)\n\n    if input.dim() == 3 and mode == "nearest-exact":\n        return torch._C._nn._upsample_nearest_exact1d(input, output_size, scale_factors)\n    if input.dim() == 4 and mode == "nearest-exact":\n        return torch._C._nn._upsample_nearest_exact2d(input, output_size, scale_factors)\n    if input.dim() == 5 and mode == "nearest-exact":\n        return torch._C._nn._upsample_nearest_exact3d(input, output_size, scale_factors)\n\n    if input.dim() == 3 and mode == "area":\n        assert output_size is not None\n        return adaptive_avg_pool1d(input, output_size)\n    if input.dim() == 4 and mode == "area":\n        assert output_size is not None\n        return adaptive_avg_pool2d(input, output_size)\n    if input.dim() == 5 and mode == "area":\n        assert output_size is not None\n        return adaptive_avg_pool3d(input, output_size)\n\n    if input.dim() == 3 and mode == "linear":\n        assert align_corners is not None\n        return torch._C._nn.upsample_linear1d(input, output_size, align_corners, scale_factors)\n    if input.dim() == 4 and mode == "bilinear":\n        assert align_corners is not None\n        if antialias:\n            return torch._C._nn._upsample_bilinear2d_aa(input, output_size, align_corners, scale_factors)\n        # Two levels are necessary to prevent TorchScript from touching\n        # are_deterministic_algorithms_enabled.\n        if not torch.jit.is_scripting():\n            if torch.are_deterministic_algorithms_enabled() and input.is_cuda:\n                # Use slow decomp whose backward will be in terms of index_put\n                # "..., 8192) = 8192
read@SYS(3, "nsformer Networks`:\n        https://arxiv.org/abs/1506.02025\n\n    .. warning::\n        When ``align_corners = True``, the grid positions depend on the pixel\n        size relative to the input image size, and so the locations sampled by\n        :func:`grid_sample` will differ for the same input given at different\n        resolutions (that is, after being upsampled or downsampled).\n        The default behavior up to version 1.2.0 was ``align_corners = True``.\n        Since then, the default behavior has been changed to ``align_corners = False``,\n        in order to bring it in line with the default for :func:`interpolate`.\n    .. warning::\n        When ``align_corners = True``, 2D affine transforms on 1D data and\n        3D affine transforms on 2D data (that is, when one of the spatial\n        dimensions has unit size) are ill-defined, and not an intended use case.\n        This is not a problem when ``align_corners = False``.\n        Up to version 1.2.0, all grid points along a unit dimension were\n        considered arbitrarily to be at ``-1``.\n        From version 1.3.0, under ``align_corners = True`` all grid points\n        along a unit dimension are considered to be at ``0``\n        (the center of the input image).\n    """\n    if has_torch_function_unary(theta):\n        return handle_torch_function(affine_grid, (theta,), theta, size, align_corners=align_corners)\n    if align_corners is None:\n        warnings.warn(\n            "Default grid_sample and affine_grid behavior has changed "\n            "to align_corners=False since 1.3.0. Please specify "\n            "align_corners=True if the old behavior is desired. "\n            "See the documentation of grid_sample for details."\n        )\n        align_corners = False\n\n    # enforce floating point dtype on theta\n    if not theta.is_floating_point():\n        raise ValueError(f"Expected theta to have floating point type, but got {theta.dtype}")\n    # check that shapes and sizes match\n    if len(size) == 4:\n        if theta.dim() != 3 or theta.shape[-2] != 2 or theta"..., 8192) = 8192
read@SYS(3, "ry=pin_memory,\n        requires_grad=requires_grad,\n    )\n\n\n@register_meta([aten.take.default, aten.take.out])\n@out_wrapper()\ndef meta_take(self, index):\n    # Type and device checks\n    torch._check(\n        index.dtype == torch.long,\n        lambda: f"take(): Expected a long tensor for index, but got {index.dtype}",\n    )\n    # Index checks\n    torch._check_index(\n        not (self.numel() == 0 and index.numel() != 0),\n        lambda: "take(): tried to take from an empty tensor",\n    )\n    return self.new_empty(index.shape)\n\n\n@register_meta([aten.linalg_cross.default, aten.linalg_cross.out])\n@out_wrapper()\ndef linalg_cross(self, other, *, dim=-1):\n    x_d = self.ndim\n    y_d = other.ndim\n    torch._check(\n        x_d == y_d,\n        lambda: "linalg.cross: inputs must have the same number of dimensions.",\n    )\n    torch._check(\n        self.size(dim) == 3 and other.size(dim) == 3,\n        lambda: (\n            f"linalg.cross: inputs dimension {dim} must have length 3. "\n            f"Got {self.size(dim)} and {other.size(dim)}"\n        ),\n    )\n    out_shape = _broadcast_shapes(self.shape, other.shape)\n    return self.new_empty(out_shape)\n\n\n@register_meta(aten.linalg_matrix_exp)\n@out_wrapper()\ndef linalg_matrix_exp(self):\n    squareCheckInputs(self, "linalg.matrix_exp")\n    checkFloatingOrComplex(self, "linalg.matrix_exp")\n    return torch.empty_like(self, memory_format=torch.contiguous_format)\n\n\n@register_meta(\n    [aten.cummax.default, aten.cummax.out, aten.cummin.default, aten.cummin.out]\n)\n@out_wrapper("values", "indices")\ndef cummaxmin(self, dim):\n    values = torch.empty(self.shape, device=self.device, dtype=self.dtype)\n    indices = torch.empty(self.shape, device=self.device, dtype=torch.int64)\n    if self.numel() != 0 and self.ndim != 0:\n        # Checks that dim is within bounds\n        maybe_wrap_dim(dim, self.ndim)\n    return values, indices\n\n\n@register_meta([aten.logcumsumexp.default, aten.logcumsumexp.out])\n@out_wrapper()\ndef logcumsumexp(self, dim):\n    # Checks that dim is within bounds\n    maybe_"..., 8192) = 8192
